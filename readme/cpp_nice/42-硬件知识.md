
1. 寄存器类型，寄存器宽度，
2. 缓存行，缓存一致性，缓存满载比
3. 数据局部性

===

# Hardware Basis
## LLC

Last Level Cache（LLC）：顾名思义，是处理器中多级缓存体系中的最后一级缓存。在现代处理器中，缓存通常分为几个级别，例如 L1、L2 和 L3，其中L1是最接近CPU核心的，拥有最快的访问速度但容量较小，而L3通常是最后一级缓存，有时也被称为LLC。

LLC 的特点是容量较大，可以存储更多的数据，但是访问速度相对于 L1 和 L2 缓存来说较慢。**LLC 的主要作用是减少对主内存的访问次数。**

缓存访问：当CPU执行程序并访问数据时，它会自动尝试从最接近的缓存级别（即 L1 ）获取数据。如果数据不在 L1 缓存中，它会继续查找 L2 缓存，然后是 `LLC`。这个过程称为缓存查找或缓存访问。

`LLC` 是最后一级缓存，通常是共享缓存，意味着它被处理器上的所有核心共享。

尽管程序员不能直接控制数据在哪个缓存级别上存储，但可以**通过编写高效的代码来间接影响缓存的使用效率**。

## 数据预取

预取器尝试预测程序将要访问的数据，并提前将其加载到缓存中。有效的预取可以减少缓存未命中和等待内存访问的时间。

## 缓存感知算法 ***

对于需要访问大量数据的算法，可以使用**分块算法**来提高**缓存命中率**。 ***

## Cache Lines

缓存行是缓存加载和存储数据的基本单位。

CPU 缓存是以**缓存行（cache lines）**为单位组织的（加载到缓存的），当程序访问一个内存地址时，整个缓存行都会被加载到缓存中（因为数据局部性原理，访问这个位置元素时，认为相邻的数据也会被访问到）。因此，如果程序能够连续访问存储在相邻内存地址上的数据，就可以充分利用缓存行，减少对主内存的访问（减少了内存事务），从而提高性能。

**缓存行**中的数据来源于主内存 (Main Memory)。 当 CPU 需要访问某个内存地址的数据时，会先检查缓存中是否已经存在该数据。如果存在（缓存命中），则直接从缓存中读取数据；如果不存在（缓存未命中），则需要**从主内存中读取数据并将包含该数据的整个缓存行加载到缓存中**。***

当发生缓存未命中时，CPU 通常会加载内存整个缓存行，而不是仅仅加载所需的数据。**缓存行的大小**通常为 64 字节或 128 字节。 加载的缓存行**起始于**与所需地址对齐的缓存行边界。例如，如果缓存行大小为 64 字节，所需地址为 100，则会加载地址 64-127 的缓存行。 这是因为内存访问通常具有空间局部性，即访问一个地址后很可能访问附近的地址。加载整个缓存行可以减少未来缓存未命中的次数。

数据以固定大小的块从主内存加载到缓存中。 缓存行中的地址是连续的内存地址，它们构成了一个缓存行的大小。

为了提高缓存的利用率，通常需要将数据结构对齐到缓存行边界。 这意味着数据结构的**起始地址必须是缓存行大小的倍数**。 **例如，如果缓存行大小为 64 字节，则数据结构的起始地址必须是 64 的倍数。**

## Out-of-Order Execution

允许处理器根据资源的可用性而不是指令的顺序来执行指令。这可以减少由于数据依赖性导致的空闲周期。


## CMU 缓存管理单元

在实际的硬件执行中，是否将数据写入全局内存或保留在缓存中，并**不是由 MLIR 代码直接决定的，而是由硬件的内存层次结构和缓存策略决定的**。在实际执行时，硬件的**缓存管理单元**（Cache Management Unit, CMU）会根据**缓存替换策略**（如最近最少使用（LRU）策略）来自动管理数据是否存储在缓存中。开发者通常无法直接控制这一行为，但可以通过编写高效的代码来（**利用**）提高数据保留在缓存中的概率。

如何利用这一硬件特点？答：将大的张量切为小的张量（tiling）

## SIMD（单指令多数据）指令集 期望处理什么样的数据？

## 数据局部性  ***

数据局部性（Data Locality）是指程序在运行时访问数据的模式，它与数据在内存中的物理布局有关。数据局部性的好坏直接影响程序的性能，因为现代计算机的内存层次结构设计是利用数据局部性来提高处理速度的。数据局部性主要有两种类型：

1. 时间局部性（Temporal Locality）： 时间局部性指的是程序在**短时间内多次访问相同的数据。如果一个数据项被频繁访问，它很可能在CPU缓存中被保留**，从而加快后续的访问速度。
2. 空间局部性（Spatial Locality）： 空间局部性指的是程序在短时间内访问邻近的数据项。由于计算机通常会**预取**一块内存区域到缓存中，因此**如果数据项在内存中是连续存储的，那么访问一个数据项时，其附近的数据也可能已经被加载到缓存中。**

（计算机程序通常遵循局部性原理，即最近访问的数据很可能在不久的将来再次被访问（时间局部性），以及相邻的数据项很可能被连续访问（空间局部性）。）

如何充分利用数据局部性：***

1. 循环交换（Loop Interchange）： 通过改变嵌套循环的顺序，可以提高访问数组时的空间局部性。例如，对于多维数组，确保内层循环沿着连续的内存地址进行迭代。
2. 块划分（Blocking）或循环分块（Loop Tiling）： 将大的数据集分割成小块，使得**每个小块可以完全装入缓存中**。这样可以减少缓存失效的次数，并提高时间局部性。
3. 数组融合（Array Fusion）： 将多个独立的数组操作合并到一个循环中，这样可以减少对数组的总体访问次数，并提高时间局部性。
4. 预取（Prefetching）： 在数据被访问之前，提前将其加载到缓存中。这可以是编译器自动完成的，也可以通过编写代码手动实现。
5. 数据结构选择： 选择合适的数据结构以提高数据局部性。例如，使用数组而不是链表可以提高空间局部性，因为数组元素在内存中是连续存储的。
6. 避免大跨度访问： 尽量避免在迭代过程中访问相隔很远的内存位置，这样可以减少缓存行的加载和替换。
7. 减少不必要的数据复制： 直接在原始数据上操作，而不是创建多个副本，可以减少内存带宽的需求，并提高缓存的有效利用。


## 缓存满载比

缓存满载比例（Cache Load Factor）或缓存使用率是一个衡量缓存效率的指标，它表示缓存中已经被占用的空间与缓存总容量的比例。

在某些缓存系统中，当缓存满载比例达到一定阈值（如70% ~ 90%）时，可能会触发清理机制，以避免缓存过度填满导致性能下降。

1. 如果缓存满载比例太低，可能意味着缓存的容量过大，但你没有充分利用资源。
2. 如果缓存满载比例太高，可能会导致缓存频繁替换，增加缓存未命中的次数，从而降低缓存的效率。（why？）

  - 有限的空间：缓存的大小是有限的，当缓存满载比例高时，意味着大部分缓存空间已经被占用。
  - 新的数据请求：当新的数据请求到来时，如果请求的数据不在缓存中（缓存未命中），缓存必须为新数据腾出空间。如果缓存已经很满，就需要替换掉（通过替换策略）一些现有的数据。
  - 替换策略：缓存通常使用某种替换策略来决定哪些数据应该被保留，哪些应该被替换。最近最少使用（LRU）、先进先出（FIFO）和随机替换等。当缓存满载时，这些策略会更频繁地触发替换。
  - 局部性原理：见上述。当缓存满载比例高时，新请求的数据可能会替换掉那些很快会再次被访问的数据，从而导致更多的缓存未命中。
  - 抖动（Thrashing）：在极端情况下，当缓存满载比例非常高时，可能会发生抖动现象。**这是指缓存频繁替换数据，但替换出去的数据又很快被再次请求，导致缓存性能急剧下降**。
  
  综上，缓存满载比 不能太高，经验值：70%

根据 cache 的基本工作原理，当 cpu 发出访问但是没有在在 cache 中命中时，**硬件会判断 cache 是否满**，若是，硬件会根据替换算法腾出空间。所以需要设置一个满载比。

## cache 命中率

表达欲访问的信息已在 cache 中的比例。假设一个程序执行期间 cache 总命中次数是 n，访问主存（因为 cache miss 了所以访问主主存）次数是 N，那么命中率 `H=n/(n+N)`。
假设 t1 是 cache 访问的时间， t2 是访问主存时间，则系统 的平均访问时间 是 `H*t1 + (1-H)*t2`。


## 缓存一致性

是指在多处理器系统或多核系统中，**多个处理器或核心共享同一块内存时，确保所有处理器对共享内存数据的访问都能看到一致的结果**。 如果没有缓存一致性，不同的处理器可能会看到不同的数据版本，导致程序出现错误。

想象一下，两个处理器都缓存了同一个内存位置的数据。如果一个处理器修改了该位置的数据，那么其他处理器必须能够感知到这个变化，并更新它们自己的缓存，以保持数据的一致性。 这**需要通过特定的协议来实现**，例如：

- 写无效 (Write-Invalidate): 当一个处理器写入共享数据时，其他处理器缓存中的相应数据会被失效（invalidate），下次访问时需要重新从内存或其他处理器缓存中获取最新数据。
- 写更新 (Write-Update): 当一个处理器写入共享数据时，其他处理器缓存中的相应数据会被更新为最新的值。

缓存一致性协议的实现方式会影响系统的性能和复杂性。

## 合并访问 (Memory Access Coalescing)  ***

内存访问合并是指通过**优化内存访问模式**，减少对内存的访问次数，从而提高程序性能的技术。 它主要关注的是如何将多个小的、分散的内存访问合并成较少次数的大块内存访问。

## 向量寄存器

向量寄存器是CPU中用于存储一组数据元素的寄存器，它们支持 SIMD 指令。

1. 向量寄存器数量
2. CPU 的最大向量宽度（maxVectorWidth）向量寄存器宽度

指 CPU 可以在单个向量化指令中同时处理的最大数据元素数量。这个指标通常以位（bits）为单位，表示 CPU SIMD 指令集的向量寄存器的最大宽度。它影响了向量化的效率和代码的优化策略。

例如，如果一个 CPU 的最大向量宽度是 256 位，那么它可以在一个 SIMD 指令中处理 4 个 64 位的双精度浮点数（4 x 64 = 256），或者 8 个 32 位的单精度浮点数（8 x 32 = 256）。

**最大向量宽度**是衡量 CPU 并行处理能力的一个重要指标。随着 SIMD 指令集的发展，如 Intel 的 AVX（Advanced Vector Extensions）和 AVX-512，以及 ARM 的 NEON，现代CPU的最大向量宽度已经从**128**位增加到**256**位，再到**512**位（spr的）。


## 寄存器 （General-Purpose Registers）& 向量寄存器（Vector Registers）& Tiles register

General-Purpose Registers, GPRs：

1. 大小：普通寄存器的大小通常与CPU的位宽相匹配，例如，在 32 位系统中，它们通常是 32 位的，在 64 位系统中，它们通常是 64 位的。
2. 数量：普通寄存器的数量相对较少，通常在几个到几十个之间。
3. 指令集：普通寄存器由大多数CPU指令集支持，并用于执行大多数类型的操作。

Vector Registers：

1. 用途：向量寄存器用于存储单指令多数据（SIMD）操作的数据。
2. 大小：向量寄存器通常比普通寄存器大得多，可以是128位、256位、512位或更大，以便同时存储多个数据元素。
3. 数量：向量寄存器的数量通常比普通寄存器少，但随着新的 SIMD 指令集的引入，它们的数量有所增加。
4. 指令集：向量寄存器由特定的SIMD指令集支持，如 SSE、AVX、NEON 等。

Tiles register: AMX（Advanced Matrix Extensions）指令集引入了一种新的数据结构，称为瓦片（tiles），这些瓦片可以看作是一种特殊的寄存器，用于存储矩阵数据。
如何充分利用它？评估AMX Tiles 的大小和数量，以及如何将计算映射到这些瓦片上。

## 内存抖动

内存抖动是由于**内存层次结构中不同级别存储器之间**频繁且低效的数据交换导致的系统性能显著下降现象。存储层次包括 包括CPU缓存、主内存（RAM）以及磁盘上的虚拟内存（如 交换空间：swap space）等。

简单讲，即不同存储层次之间的数据频繁地交换，来回移动，从而引发内存抖动。特指：RAM 到磁盘上 Swap space 之间来回移动，导致缓存命中率下降。内存抖动主要指 RAM 与磁盘交换空间之间的频繁交换。

设计和优化程序时，应特别注意数据访问模式和资源管理，以保持良好的系统性能。

如何避免内存抖动？

答：

- 避免在循环中创建对象，尤其是那些生命周期短暂的对象。可以通过将对象的创建移至循环外，重用对象或使用对象池来减少内存分配和回收
- 选择适合的数据结构可以减少内存分配。例如，使用 ArrayList 或 LinkedList 代替 HashSet 可以减少不必要的内存分配和复制操作
- 动态内存分配通常伴随着额外的开销。尽可能预分配内存或使用固定大小的内存块，可以减少内存分配次数
